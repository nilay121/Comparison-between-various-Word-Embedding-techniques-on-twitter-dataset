{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ComparisonBetweenEmbeddingLayers_Glove_w2v.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyHz2yMBeLki"
      },
      "source": [
        "<b>In this notebook we will make a comparison between the various word embedding techniques mainly embedding Layer of Keras, GloVe and Word2Vec on twitter dataset<b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn03jzTPgQ4q"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K194mRBhgTHy",
        "outputId": "7da519e3-1d34-45fd-8201-8711b09f706a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers.recurrent import LSTM,GRU\n",
        "from keras.layers import Dense,Dropout,BatchNormalization,Bidirectional,Embedding,Flatten\n",
        "from keras.layers import Conv1D,MaxPool1D,GlobalAveragePooling1D\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords=stopwords.words(\"english\")\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJT15Fh0lvDE"
      },
      "source": [
        "train=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ComparisonB wEmbedding techniques/Twitter_Data.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQP3e5w5qYjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00afb457-94d8-46c2-9d18-dc83593538c7"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162980, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HporIGaylaES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8df09723-dc34-46d9-8029-a4b5a02d9518"
      },
      "source": [
        "train.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  category\n",
              "0  when modi promised “minimum government maximum...      -1.0\n",
              "1  talk all the nonsense and continue all the dra...       0.0\n",
              "2  what did just say vote for modi  welcome bjp t...       1.0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XTlLIPD3bgd"
      },
      "source": [
        "# Changing the category labels\n",
        "target=[]\n",
        "for i in train['category']:\n",
        "  if i==-1.0:\n",
        "    target.append(0)\n",
        "  elif i==0.0:\n",
        "    target.append(1)\n",
        "  else:\n",
        "    target.append(2)\n",
        "\n",
        "train['target']=target"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02CHdqm1laHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08d0ca6-45a3-44cb-e48b-e20e034cc2d2"
      },
      "source": [
        "# The dataset looks imbalanced \n",
        "train['target'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    72257\n",
              "1    55213\n",
              "0    35510\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ0P5lVclaKc"
      },
      "source": [
        "def cleaning(text):\n",
        "  cleaned_text=[]\n",
        "  lemm_obj=WordNetLemmatizer()\n",
        "  tokens_list=re.split(\" \",str(text))\n",
        "  for token in tokens_list:\n",
        "    token_small=token.lower() #converting to lower case\n",
        "    punc_removed=re.sub(\"[^a-z A-Z 0-9]\",'',token_small)\n",
        "\n",
        "    if punc_removed not in stopwords:\n",
        "      cleaned_text.append(lemm_obj.lemmatize(punc_removed))\n",
        "  clean_text=\" \".join(cleaned_text)\n",
        "  return clean_text\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDBLo5_alaNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a61701-5f74-49da-fcee-b9d4b1cecb08"
      },
      "source": [
        "%%time\n",
        "train[\"Cleaned tweet\"]=train[\"clean_text\"].apply(cleaning)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25.5 s, sys: 283 ms, total: 25.8 s\n",
            "Wall time: 25.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFugEOVGpbZk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "8ea84312-64ab-4a50-bd23-1687eb9039e5"
      },
      "source": [
        "train.head(3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "      <th>target</th>\n",
              "      <th>Cleaned tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>modi promised minimum government maximum gover...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>talk nonsense continue drama vote modi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>say vote modi  welcome bjp told rahul main cam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  ...                                      Cleaned tweet\n",
              "0  when modi promised “minimum government maximum...  ...  modi promised minimum government maximum gover...\n",
              "1  talk all the nonsense and continue all the dra...  ...            talk nonsense continue drama vote modi \n",
              "2  what did just say vote for modi  welcome bjp t...  ...  say vote modi  welcome bjp told rahul main cam...\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5fSSrnbvThA"
      },
      "source": [
        "Lets now create one hot encoding of the cleaned tweet using keras tokenizer class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FgMYY0Kpbcn"
      },
      "source": [
        "tokenizer_obj=Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(train['Cleaned tweet'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs-iZ7HivywR"
      },
      "source": [
        "# Looking at some of the key value pairs generated\n",
        "\n",
        "# tokenizer_obj.word_index.keys()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajed0aARwPVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff44f04-a27c-4a17-d0f5-713c6a723da0"
      },
      "source": [
        "#Defining the vocabulary size for training embedding layer\n",
        "vocab_size=len(tokenizer_obj.word_index)+1\n",
        "print(vocab_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py65Rya-xS3p"
      },
      "source": [
        "def one_hot_encoding_text(df_list):\n",
        "  encoded_tweets=[]\n",
        "  for tweets in df_list:\n",
        "    encoded_tweets.append(tokenizer_obj.texts_to_sequences([tweets])[0])\n",
        "  return encoded_tweets"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj9UddhWxS6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849dc8a1-2daa-4386-99ab-e39a33ec2dbb"
      },
      "source": [
        "%%time\n",
        "encoded_tweet=np.array(one_hot_encoding_text(train['Cleaned tweet']))\n",
        "# test_tweet=np.array(one_hot_encoding_text(test['Cleaned tweet'])) #test data"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.03 s, sys: 48.3 ms, total: 3.08 s\n",
            "Wall time: 3.09 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud7BWB40wQxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96c74c7-5c08-4e3b-a04e-a2e7d30a050c"
      },
      "source": [
        "# Adding padding to make dimensions of all the rows same\n",
        "max_length=100\n",
        "padded_encTweet=pad_sequences(encoded_tweet,maxlen=max_length,padding=\"post\") #train data\n",
        "# padded_testt=pad_sequences(test_tweet,maxlen=max_length,padding=\"post\") #test data\n",
        "padded_encTweet[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1,   239,   633,    27,  1541,   727,  1002,  1243,  1067,\n",
              "          52, 15427,   105,    41,    14,    24,   976,   105,   404,\n",
              "        3642,  5050,  1090,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmfBYWwL3PcS"
      },
      "source": [
        "Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2e_wOCA4cPj"
      },
      "source": [
        "X=padded_encTweet\n",
        "y=train['target']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H-8uZYb3PJQ"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxV4D9Tq3IA_"
      },
      "source": [
        "<h1>Embedding Layer</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6P_g9dkxS9T"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "#Embedding Layer\n",
        "model.add(Embedding(input_dim=vocab_size,output_dim=300,input_length=max_length))\n",
        "model.add(Dense(units=500,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(units=300,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "\n",
        "model.add(Flatten()) # To flatten the 3d matrix to 2d ,can use globalpooling1d also\n",
        "model.add(Dense(units=3,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx6ld74BxS_x",
        "outputId": "537ade09-ef62-42dd-f5a9-71fad31ec666"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 300)          34929900  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200, 500)          150500    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 200, 500)          2000      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200, 500)          0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 200, 300)          150300    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 200, 300)          1200      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200, 200)          60200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 200, 200)          800       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200, 200)          0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200, 200)          40200     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 40000)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 120003    \n",
            "=================================================================\n",
            "Total params: 35,455,103\n",
            "Trainable params: 35,453,103\n",
            "Non-trainable params: 2,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoFSIh830Lpz"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRPj3huc0Ls6",
        "outputId": "77b75d98-6444-415d-e0dd-05540b44d9b9"
      },
      "source": [
        "#The loss is still dreacreasing and the accuracy is increasing, so train it for at least 30 epochs to get a decent accuracy\n",
        "model.fit(x=x_train,y=y_train,epochs=5,batch_size=512,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "223/223 [==============================] - 101s 436ms/step - loss: 1.3765 - accuracy: 0.4668 - val_loss: 1.4026 - val_accuracy: 0.3389\n",
            "Epoch 2/5\n",
            "223/223 [==============================] - 96s 431ms/step - loss: 0.7958 - accuracy: 0.6512 - val_loss: 1.2064 - val_accuracy: 0.5199\n",
            "Epoch 3/5\n",
            "223/223 [==============================] - 96s 432ms/step - loss: 0.4946 - accuracy: 0.8282 - val_loss: 0.4720 - val_accuracy: 0.8231\n",
            "Epoch 4/5\n",
            "223/223 [==============================] - 97s 433ms/step - loss: 0.3561 - accuracy: 0.8898 - val_loss: 0.4008 - val_accuracy: 0.8745\n",
            "Epoch 5/5\n",
            "223/223 [==============================] - 96s 432ms/step - loss: 0.2950 - accuracy: 0.9111 - val_loss: 0.4150 - val_accuracy: 0.8666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe960032190>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLrZ0q_y7Jeo"
      },
      "source": [
        "<h1> Using Conv and Pooling layer to check if it helps </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWemeVSG0LwC"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "#Embedding Layer\n",
        "model.add(Embedding(input_dim=vocab_size,output_dim=300,input_length=max_length))\n",
        "model.add(Dense(units=500,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(units=300,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Conv1D(filters=300,kernel_size=3,activation='relu'))\n",
        "model.add(MaxPool1D(pool_size=2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Conv1D(filters=100,kernel_size=3,activation='relu'))\n",
        "model.add(MaxPool1D(pool_size=3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Flatten()) # To flatten the 3d matrix to 2d ,can use globalpooling1d also\n",
        "model.add(Dense(units=3,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BF9wnye0LzE"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USi61hkS0L2J",
        "outputId": "45c5df87-41d8-4559-8553-cff72b8991ff"
      },
      "source": [
        "#The loss is still dreacreasing and the accuracy is increasing, so train it for at least 30 epochs to get a decent accuracy\n",
        "model.fit(x=x_train,y=y_train,epochs=5,batch_size=512,validation_data=(x_test,y_test))\n",
        "\n",
        "# Epoch 1/5\n",
        "# 223/223 [==============================] - 165s 606ms/step - loss: 1.1508 - accuracy: 0.4791 - val_loss: 1.6432 - val_accuracy: 0.3389\n",
        "# Epoch 2/5\n",
        "# 223/223 [==============================] - 134s 600ms/step - loss: 0.8148 - accuracy: 0.6325 - val_loss: 1.4757 - val_accuracy: 0.5078\n",
        "# Epoch 3/5\n",
        "# 223/223 [==============================] - 133s 598ms/step - loss: 0.5691 - accuracy: 0.7765 - val_loss: 0.7508 - val_accuracy: 0.6751\n",
        "# Epoch 4/5\n",
        "# 223/223 [==============================] - 133s 598ms/step - loss: 0.5024 - accuracy: 0.8135 - val_loss: 0.6313 - val_accuracy: 0.7545\n",
        "# Epoch 5/5\n",
        "# 223/223 [==============================] - 133s 598ms/step - loss: 0.3840 - accuracy: 0.8760 - val_loss: 0.4831 - val_accuracy: 0.8462\n",
        "\n",
        "# <keras.callbacks.History at 0x7fe8f3ec6650>\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "223/223 [==============================] - 165s 606ms/step - loss: 1.1508 - accuracy: 0.4791 - val_loss: 1.6432 - val_accuracy: 0.3389\n",
            "Epoch 2/5\n",
            "223/223 [==============================] - 134s 600ms/step - loss: 0.8148 - accuracy: 0.6325 - val_loss: 1.4757 - val_accuracy: 0.5078\n",
            "Epoch 3/5\n",
            "223/223 [==============================] - 133s 598ms/step - loss: 0.5691 - accuracy: 0.7765 - val_loss: 0.7508 - val_accuracy: 0.6751\n",
            "Epoch 4/5\n",
            "223/223 [==============================] - 133s 598ms/step - loss: 0.5024 - accuracy: 0.8135 - val_loss: 0.6313 - val_accuracy: 0.7545\n",
            "Epoch 5/5\n",
            "223/223 [==============================] - 133s 598ms/step - loss: 0.3840 - accuracy: 0.8760 - val_loss: 0.4831 - val_accuracy: 0.8462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8f3ec6650>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QnesAyo_R_s"
      },
      "source": [
        "Though in this case the presence of pooling layers isn't helping the model that much but sometimes pooling also helps in increasing the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KAgfzuJ_EdW"
      },
      "source": [
        "<h1>Using Glove</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdZSq57eBYN4"
      },
      "source": [
        "The data in the glove text file that we have downloaded from the Standford website is in key value pair, where the word is represented as the key and the 100 dimensional vector is as the value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyPMkNv8B2RK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b924cf-4c9d-4b48-b019-811232fcb526"
      },
      "source": [
        "%%time\n",
        "#Lets first load the file and look at first few words\n",
        "\n",
        "data_file = open(\"/content/drive/MyDrive/Colab Notebooks/ComparisonB wEmbedding techniques/glove.6B.100d.txt\",encoding=\"UTF-8\")\n",
        "\n",
        "count=0\n",
        "for i in data_file:\n",
        "  if count<=3:\n",
        "    print(i)\n",
        "  else:\n",
        "    break\n",
        "  count+=1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
            "\n",
            ", -0.10767 0.11053 0.59812 -0.54361 0.67396 0.10663 0.038867 0.35481 0.06351 -0.094189 0.15786 -0.81665 0.14172 0.21939 0.58505 -0.52158 0.22783 -0.16642 -0.68228 0.3587 0.42568 0.19021 0.91963 0.57555 0.46185 0.42363 -0.095399 -0.42749 -0.16567 -0.056842 -0.29595 0.26037 -0.26606 -0.070404 -0.27662 0.15821 0.69825 0.43081 0.27952 -0.45437 -0.33801 -0.58184 0.22364 -0.5778 -0.26862 -0.20425 0.56394 -0.58524 -0.14365 -0.64218 0.0054697 -0.35248 0.16162 1.1796 -0.47674 -2.7553 -0.1321 -0.047729 1.0655 1.1034 -0.2208 0.18669 0.13177 0.15117 0.7131 -0.35215 0.91348 0.61783 0.70992 0.23955 -0.14571 -0.37859 -0.045959 -0.47368 0.2385 0.20536 -0.18996 0.32507 -1.1112 -0.36341 0.98679 -0.084776 -0.54008 0.11726 -1.0194 -0.24424 0.12771 0.013884 0.080374 -0.35414 0.34951 -0.7226 0.37549 0.4441 -0.99059 0.61214 -0.35111 -0.83155 0.45293 0.082577\n",
            "\n",
            ". -0.33979 0.20941 0.46348 -0.64792 -0.38377 0.038034 0.17127 0.15978 0.46619 -0.019169 0.41479 -0.34349 0.26872 0.04464 0.42131 -0.41032 0.15459 0.022239 -0.64653 0.25256 0.043136 -0.19445 0.46516 0.45651 0.68588 0.091295 0.21875 -0.70351 0.16785 -0.35079 -0.12634 0.66384 -0.2582 0.036542 -0.13605 0.40253 0.14289 0.38132 -0.12283 -0.45886 -0.25282 -0.30432 -0.11215 -0.26182 -0.22482 -0.44554 0.2991 -0.85612 -0.14503 -0.49086 0.0082973 -0.17491 0.27524 1.4401 -0.21239 -2.8435 -0.27958 -0.45722 1.6386 0.78808 -0.55262 0.65 0.086426 0.39012 1.0632 -0.35379 0.48328 0.346 0.84174 0.098707 -0.24213 -0.27053 0.045287 -0.40147 0.11395 0.0062226 0.036673 0.018518 -1.0213 -0.20806 0.64072 -0.068763 -0.58635 0.33476 -1.1432 -0.1148 -0.25091 -0.45907 -0.096819 -0.17946 -0.063351 -0.67412 -0.068895 0.53604 -0.87773 0.31802 -0.39242 -0.23394 0.47298 -0.028803\n",
            "\n",
            "of -0.1529 -0.24279 0.89837 0.16996 0.53516 0.48784 -0.58826 -0.17982 -1.3581 0.42541 0.15377 0.24215 0.13474 0.41193 0.67043 -0.56418 0.42985 -0.012183 -0.11677 0.31781 0.054177 -0.054273 0.35516 -0.30241 0.31434 -0.33846 0.71715 -0.26855 -0.15837 -0.47467 0.051581 -0.33252 0.15003 -0.1299 -0.54617 -0.37843 0.64261 0.82187 -0.080006 0.078479 -0.96976 -0.57741 0.56491 -0.39873 -0.057099 0.19743 0.065706 -0.48092 -0.20125 -0.40834 0.39456 -0.02642 -0.11838 1.012 -0.53171 -2.7474 -0.042981 -0.74849 1.7574 0.59085 0.04885 0.78267 0.38497 0.42097 0.67882 0.10337 0.6328 -0.026595 0.58647 -0.44332 0.33057 -0.12022 -0.55645 0.073611 0.20915 0.43395 -0.012761 0.089874 -1.7991 0.084808 0.77112 0.63105 -0.90685 0.60326 -1.7515 0.18596 -0.50687 -0.70203 0.66578 -0.81304 0.18712 -0.018488 -0.26757 0.727 -0.59363 -0.34839 -0.56094 -0.591 1.0039 0.20664\n",
            "\n",
            "CPU times: user 5.49 ms, sys: 1.09 ms, total: 6.58 ms\n",
            "Wall time: 907 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8zpbGPBDGpc",
        "outputId": "d6b5ebcf-7ca3-49e7-cc8c-a816ee87f5da"
      },
      "source": [
        "%%time\n",
        "#Now lets create a dictionary having words as keys and vectors as value\n",
        "\n",
        "glove_dict={}\n",
        "for i in data_file:\n",
        "  splitted_data=i.split()\n",
        "  word=splitted_data[0]\n",
        "  vect=np.array(splitted_data[1:],dtype=\"float32\")\n",
        "  glove_dict[word]=vect\n",
        "\n",
        "print(f\"The length of the dictionary created is \",{len(glove_dict)})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the dictionary created is  {399995}\n",
            "CPU times: user 11.7 s, sys: 670 ms, total: 12.4 s\n",
            "Wall time: 12.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w94pZfLEN4TV"
      },
      "source": [
        "Now lets one hot encode encode the cleaned tweets on the basis of this glove vectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7EppDqdowNO",
        "outputId": "234c3dff-d69f-4bfa-c5e6-9f44a43f2b30"
      },
      "source": [
        "train['target'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn6_dfgDDGxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6715448-d6f8-499b-a9e9-4688d73fd81f"
      },
      "source": [
        "%%time\n",
        "def OneHotUsingGlove(df_data):\n",
        "  OneHotVect=[]\n",
        "  noVec=[]\n",
        "  y_new=[]\n",
        "  counter=0\n",
        "  for j in df_data:\n",
        "    temp=[]\n",
        "    tokens_list=j.split()\n",
        "    for i in tokens_list:\n",
        "      if i in glove_dict.keys():\n",
        "        temp.append(glove_dict[i])\n",
        "      else:\n",
        "        noVec.append(i)\n",
        "    if len(temp) != 0:\n",
        "      OneHotVect.append(np.array(temp))\n",
        "      y_new.append(train['target'][counter])\n",
        "      counter+=1\n",
        "  return np.array(OneHotVect),noVec,y_new\n",
        "\n",
        "Encoded_vect,exemptedWords,y_new=OneHotUsingGlove(train['Cleaned tweet'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.33 s, sys: 553 ms, total: 4.89 s\n",
            "Wall time: 4.88 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4nYXobzDG0Q"
      },
      "source": [
        "# print(exemptedWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLOIN5OujBhC"
      },
      "source": [
        "added_vec=[]\n",
        "counter=0\n",
        "for i in range(0,len(Encoded_vect)):\n",
        "  added_vec.append(Encoded_vect[i].sum(axis=0).reshape(1,100))\n",
        "\n",
        "added_vec=np.array(added_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l4JsCJkVdDa"
      },
      "source": [
        "One thing we can see that most of the words that didn't had a glove vector are either hindi word or some misspelled words, however it might be that the performance of glove might be affected because we don't have word vectors for hindi words in this case whereas in the embedding layer since we trained our own vocabulary so it might be that in that case the performance could be little good because we also had word vectors for the hindi words as well in that case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvAwif_4mynO",
        "outputId": "1a2203cc-e39d-4aeb-84ca-14234c4f8034"
      },
      "source": [
        "added_vec[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "691G0DEjr8KF",
        "outputId": "720dc33d-19df-45bc-ea0e-6c684d184faa"
      },
      "source": [
        "type(y_new[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeIaoifmDG2S"
      },
      "source": [
        "X=added_vec.reshape(-1,100)\n",
        "y=np.array(y_new)\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iugpr1sAuEJM"
      },
      "source": [
        "scalar=StandardScaler()\n",
        "x_scaled=scalar.fit_transform(x_train)\n",
        "x_valid_scaled=scalar.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP_pnz-oDG4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ef1cd5-00a0-4c55-c098-3f02cb944a67"
      },
      "source": [
        "#training simple ANN\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(500, input_dim=100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(3,activation=\"softmax\"))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 500)               50500     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 400)               200400    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 200)               80200     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3)                 603       \n",
            "=================================================================\n",
            "Total params: 331,703\n",
            "Trainable params: 331,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "159vOrwTDG6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03a55fd-474d-46ac-d3b6-df2c5694dc47"
      },
      "source": [
        "model.fit(x_scaled,y_train,batch_size=512,epochs=30,validation_data=(x_valid_scaled,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "223/223 [==============================] - 2s 7ms/step - loss: 1.0692 - accuracy: 0.4370 - val_loss: 1.0629 - val_accuracy: 0.4434\n",
            "Epoch 2/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0616 - accuracy: 0.4432 - val_loss: 1.0610 - val_accuracy: 0.4434\n",
            "Epoch 3/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0605 - accuracy: 0.4433 - val_loss: 1.0608 - val_accuracy: 0.4434\n",
            "Epoch 4/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0596 - accuracy: 0.4432 - val_loss: 1.0608 - val_accuracy: 0.4434\n",
            "Epoch 5/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0593 - accuracy: 0.4433 - val_loss: 1.0607 - val_accuracy: 0.4434\n",
            "Epoch 6/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0588 - accuracy: 0.4432 - val_loss: 1.0613 - val_accuracy: 0.4434\n",
            "Epoch 7/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0585 - accuracy: 0.4432 - val_loss: 1.0606 - val_accuracy: 0.4434\n",
            "Epoch 8/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0580 - accuracy: 0.4434 - val_loss: 1.0609 - val_accuracy: 0.4434\n",
            "Epoch 9/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0579 - accuracy: 0.4432 - val_loss: 1.0610 - val_accuracy: 0.4434\n",
            "Epoch 10/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0574 - accuracy: 0.4433 - val_loss: 1.0608 - val_accuracy: 0.4434\n",
            "Epoch 11/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0570 - accuracy: 0.4429 - val_loss: 1.0615 - val_accuracy: 0.4432\n",
            "Epoch 12/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0566 - accuracy: 0.4433 - val_loss: 1.0610 - val_accuracy: 0.4433\n",
            "Epoch 13/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0562 - accuracy: 0.4433 - val_loss: 1.0614 - val_accuracy: 0.4432\n",
            "Epoch 14/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0552 - accuracy: 0.4433 - val_loss: 1.0617 - val_accuracy: 0.4433\n",
            "Epoch 15/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0552 - accuracy: 0.4438 - val_loss: 1.0619 - val_accuracy: 0.4429\n",
            "Epoch 16/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0544 - accuracy: 0.4445 - val_loss: 1.0621 - val_accuracy: 0.4431\n",
            "Epoch 17/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0533 - accuracy: 0.4449 - val_loss: 1.0637 - val_accuracy: 0.4418\n",
            "Epoch 18/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0522 - accuracy: 0.4444 - val_loss: 1.0636 - val_accuracy: 0.4418\n",
            "Epoch 19/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0511 - accuracy: 0.4451 - val_loss: 1.0645 - val_accuracy: 0.4389\n",
            "Epoch 20/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0499 - accuracy: 0.4456 - val_loss: 1.0642 - val_accuracy: 0.4406\n",
            "Epoch 21/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0487 - accuracy: 0.4467 - val_loss: 1.0647 - val_accuracy: 0.4395\n",
            "Epoch 22/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0474 - accuracy: 0.4463 - val_loss: 1.0668 - val_accuracy: 0.4393\n",
            "Epoch 23/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0463 - accuracy: 0.4482 - val_loss: 1.0657 - val_accuracy: 0.4407\n",
            "Epoch 24/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0442 - accuracy: 0.4490 - val_loss: 1.0698 - val_accuracy: 0.4350\n",
            "Epoch 25/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0424 - accuracy: 0.4502 - val_loss: 1.0678 - val_accuracy: 0.4371\n",
            "Epoch 26/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0403 - accuracy: 0.4516 - val_loss: 1.0686 - val_accuracy: 0.4368\n",
            "Epoch 27/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0387 - accuracy: 0.4524 - val_loss: 1.0686 - val_accuracy: 0.4366\n",
            "Epoch 28/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0371 - accuracy: 0.4536 - val_loss: 1.0720 - val_accuracy: 0.4318\n",
            "Epoch 29/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0351 - accuracy: 0.4561 - val_loss: 1.0718 - val_accuracy: 0.4334\n",
            "Epoch 30/30\n",
            "223/223 [==============================] - 1s 6ms/step - loss: 1.0332 - accuracy: 0.4579 - val_loss: 1.0749 - val_accuracy: 0.4328\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec60a01790>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2J_Ao9ZHOK_"
      },
      "source": [
        "As we can see using Simple ANN with glove vectors we get a very bad training and test accuracy. So, lets try to create a non trainable embedding layer having the weights from the Glovevectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_LjQNnkHqhe"
      },
      "source": [
        "<h1>Embedding layer using Glove</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii7oVWxmvNpS"
      },
      "source": [
        "#check the upper code to understand these variables\n",
        "#here since i is starting from i=0 therefore while scripting we use i+1 since in the tokenized word\n",
        "#indexing starts from 1\n",
        "\n",
        "weight_matrix = np.zeros((vocab_size,100))\n",
        "novec=[]\n",
        "for i,word in enumerate(tokenizer_obj.word_index.keys()):\n",
        "  temp=glove_dict.get(word)\n",
        "  if temp is not None:\n",
        "    weight_matrix[i+1]=temp\n",
        "  else:\n",
        "    novec.append(word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8kDjl5bSmDb"
      },
      "source": [
        "X=padded_encTweet\n",
        "y=train['target']\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvlsrZ64QnqL",
        "outputId": "8f404f37-5f82-4bdd-cdec-3b777cf35514"
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "#Embedding Layer\n",
        "model.add(Embedding(input_dim=vocab_size,output_dim=100,input_length=max_length,weights=[weight_matrix],trainable=\"False\"))\n",
        "model.add(Dense(units=500,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(units=300,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Conv1D(filters=300,kernel_size=3,activation='relu'))\n",
        "model.add(MaxPool1D(pool_size=2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Conv1D(filters=100,kernel_size=3,activation='relu'))\n",
        "model.add(MaxPool1D(pool_size=3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Flatten()) # To flatten the 3d matrix to 2d ,can use globalpooling1d also\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 200, 100)          11643400  \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 200, 500)          50500     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 200, 500)          2000      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 200, 500)          0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 200, 300)          150300    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 200, 300)          1200      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 198, 300)          270300    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 99, 300)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 99, 300)           1200      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 99, 300)           0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 99, 200)           60200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 99, 200)           800       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 99, 200)           40200     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 99, 200)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 97, 100)           60100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 32, 100)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 32, 100)           400       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 32, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 9603      \n",
            "=================================================================\n",
            "Total params: 12,290,203\n",
            "Trainable params: 12,287,403\n",
            "Non-trainable params: 2,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu5iZqNmQntC"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjPjuJNkQnv5",
        "outputId": "0ff20a61-2b81-4f39-9651-bc32ea2d2c15"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=10,batch_size=512 ,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "223/223 [==============================] - 145s 516ms/step - loss: 1.1269 - accuracy: 0.4889 - val_loss: 1.8203 - val_accuracy: 0.3389\n",
            "Epoch 2/10\n",
            "223/223 [==============================] - 114s 513ms/step - loss: 0.7835 - accuracy: 0.6587 - val_loss: 1.9341 - val_accuracy: 0.4411\n",
            "Epoch 3/10\n",
            "223/223 [==============================] - 114s 513ms/step - loss: 0.5685 - accuracy: 0.7936 - val_loss: 6.2876 - val_accuracy: 0.3439\n",
            "Epoch 4/10\n",
            "223/223 [==============================] - 114s 513ms/step - loss: 0.4510 - accuracy: 0.8579 - val_loss: 2.1971 - val_accuracy: 0.5478\n",
            "Epoch 5/10\n",
            "223/223 [==============================] - 114s 512ms/step - loss: 0.4146 - accuracy: 0.8727 - val_loss: 1.6748 - val_accuracy: 0.5694\n",
            "Epoch 6/10\n",
            "223/223 [==============================] - 114s 513ms/step - loss: 0.3927 - accuracy: 0.8802 - val_loss: 0.3679 - val_accuracy: 0.8908\n",
            "Epoch 7/10\n",
            "223/223 [==============================] - 114s 513ms/step - loss: 0.3753 - accuracy: 0.8859 - val_loss: 0.3880 - val_accuracy: 0.8932\n",
            "Epoch 8/10\n",
            "223/223 [==============================] - 114s 513ms/step - loss: 0.3518 - accuracy: 0.8927 - val_loss: 1.5592 - val_accuracy: 0.5992\n",
            "Epoch 9/10\n",
            "223/223 [==============================] - 114s 513ms/step - loss: 0.3167 - accuracy: 0.9058 - val_loss: 0.3563 - val_accuracy: 0.8919\n",
            "Epoch 10/10\n",
            "223/223 [==============================] - 114s 512ms/step - loss: 0.2896 - accuracy: 0.9150 - val_loss: 0.3705 - val_accuracy: 0.8868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7febe50c1e10>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEANXuIoZ92B"
      },
      "source": [
        "So we can see the accuracy of Glove vectors with embedding layer is pretty good and its the best till now though glove vectors didn't had some of the hindi words in their vocabulary still it performs very good on the twitter data.\n",
        "Now, we will try to train Word2Vec model using Gensim Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGKZjiAvacL4"
      },
      "source": [
        "<h1>Word2Vec Using Gensim </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Xeb382Qnyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a3118f-4f7d-43c7-fbd8-76e413bd1704"
      },
      "source": [
        "# pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-B86fX1ro-J",
        "outputId": "f8b9e196-a5a3-4036-86a1-82e2192cc1ff"
      },
      "source": [
        "#lets first tokenize the words and convert it into sepratae lists\n",
        "\n",
        "#It does do any sort of stemming or lemmatizing, we can always create a custom function for this, but lets\n",
        "#leave it for simplicity\n",
        "\n",
        "gensim.utils.simple_preprocess('Hello my name is! N@Ilay, I am a runner')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'my', 'name', 'is', 'ilay', 'am', 'runner']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuve2VQmsq9p"
      },
      "source": [
        "gensim_tweet=[]\n",
        "for i in train['clean_text']:\n",
        "  gensim_tweet.append(gensim.utils.simple_preprocess(str(i)))\n",
        "\n",
        "train['gensim_tweet']=gensim_tweet"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "q0OP477Fu7YG",
        "outputId": "7ebf9d8c-e393-4b93-8cd1-41855130fad2"
      },
      "source": [
        "train.head(3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "      <th>target</th>\n",
              "      <th>Cleaned tweet</th>\n",
              "      <th>gensim_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>modi promised minimum government maximum gover...</td>\n",
              "      <td>[when, modi, promised, minimum, government, ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>talk nonsense continue drama vote modi</td>\n",
              "      <td>[talk, all, the, nonsense, and, continue, all,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>say vote modi  welcome bjp told rahul main cam...</td>\n",
              "      <td>[what, did, just, say, vote, for, modi, welcom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  ...                                       gensim_tweet\n",
              "0  when modi promised “minimum government maximum...  ...  [when, modi, promised, minimum, government, ma...\n",
              "1  talk all the nonsense and continue all the dra...  ...  [talk, all, the, nonsense, and, continue, all,...\n",
              "2  what did just say vote for modi  welcome bjp t...  ...  [what, did, just, say, vote, for, modi, welcom...\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ4KNRacu8Y-",
        "outputId": "35b6db56-6bc2-4dab-b906-c39ca4277256"
      },
      "source": [
        "#lets create the word2vec model\n",
        "%%time\n",
        "w2v_model= Word2Vec(sentences=train['gensim_tweet'],window=5,min_count=3,workers=4)\n",
        "w2v_model.train(train['gensim_tweet'],epochs=5,total_examples=len(train))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 35s, sys: 971 ms, total: 1min 36s\n",
            "Wall time: 53.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89LKZntB6AaN",
        "outputId": "89b759ca-3b5c-40f8-a9d9-4a659c32cede"
      },
      "source": [
        "#lets check similar word\n",
        "w2v_model.wv.most_similar('hello',topn=5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dear', 0.7226555347442627),\n",
              " ('hey', 0.6569077968597412),\n",
              " ('mam', 0.6175224184989929),\n",
              " ('maam', 0.6160340905189514),\n",
              " ('pranam', 0.588625431060791)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJGZC9CC6Adm",
        "outputId": "4b03ff06-34c4-47fe-ff55-b3feb76eb4fe"
      },
      "source": [
        "#lets see the vector representation of the word\n",
        "w2v_model.wv[\"good\"]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.7579234 ,  0.96683294,  0.48309773,  2.692498  ,  0.24553989,\n",
              "        0.52746487,  0.32010522,  3.112537  ,  1.3808085 ,  1.3502463 ,\n",
              "        0.37154937, -0.42744398, -0.23473057,  0.6549205 ,  1.4279842 ,\n",
              "        1.2216411 , -1.3362641 , -1.7412187 , -1.3088381 , -0.8881871 ,\n",
              "       -1.1485415 , -1.1617924 ,  0.01498502,  0.52090627,  0.37374774,\n",
              "       -1.4493463 ,  0.50938857, -1.1663167 , -0.14603762, -2.1022344 ,\n",
              "        1.5571824 ,  0.9696644 , -0.05373155,  2.2256715 ,  1.8663635 ,\n",
              "       -0.22856787,  1.7512127 ,  1.8316784 , -0.8983375 ,  1.1543334 ,\n",
              "        2.7531672 , -1.3410981 ,  0.13554361,  1.0550512 ,  0.20747016,\n",
              "        0.23559046, -0.28939912, -0.89447325, -0.6129041 ,  2.347943  ,\n",
              "        1.8267337 , -0.38103226,  1.2160603 ,  0.44800016,  0.91664493,\n",
              "        0.20376664, -0.50375396, -0.23011392, -2.572044  , -0.4118387 ,\n",
              "        0.30619743,  0.8000849 ,  0.743947  ,  0.18785729,  1.6524303 ,\n",
              "        1.5168678 , -0.13562828,  0.14737622,  2.7937303 ,  0.14163862,\n",
              "        1.2657483 , -0.5919355 ,  1.2164042 , -0.9149318 , -1.6141402 ,\n",
              "       -0.5147977 ,  1.5296097 , -0.8794811 , -1.5782027 , -0.39306328,\n",
              "        1.1686506 , -1.1052123 ,  0.6948091 ,  0.36196923,  0.9998506 ,\n",
              "       -2.5504508 , -1.7942742 ,  1.7612379 , -1.9649957 , -1.5610963 ,\n",
              "        0.01383541, -0.20226167, -0.67957765,  0.44599065,  0.10203946,\n",
              "       -1.5654205 , -0.9392444 , -0.5791375 ,  0.02661144,  0.23230769],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9EiOFUQ6Agh",
        "outputId": "576a4d36-f647-49b7-e617-b1ee1bd221ec"
      },
      "source": [
        "w2v_model.wv[\"king\"]-w2v_model.wv[\"man\"]+w2v_model.wv[\"woman\"]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.19628221,  1.8531872 , -0.6784609 ,  0.7182686 , -0.5344882 ,\n",
              "       -2.1931028 , -0.6790533 , -1.2975703 ,  0.04049045,  0.96968144,\n",
              "       -1.9196577 , -1.3964196 ,  0.39594972, -0.41075093,  0.15451872,\n",
              "        0.01967683, -0.3364096 , -1.2504339 , -2.322707  , -1.8248136 ,\n",
              "        2.1848774 ,  1.5554055 ,  0.27298686,  1.3110242 ,  1.8206143 ,\n",
              "        0.5060966 ,  1.9493535 ,  0.1421197 ,  1.033382  ,  1.7560831 ,\n",
              "       -1.5630133 ,  0.7653849 ,  0.31148082,  0.7013148 ,  0.52121454,\n",
              "       -1.163305  , -2.0484345 , -0.8873914 ,  0.2631318 , -2.8481276 ,\n",
              "       -0.7232118 ,  0.6034346 , -0.63455445, -2.6366854 ,  0.47316036,\n",
              "        1.302081  , -0.578097  ,  2.2107816 ,  0.34801233, -0.64011335,\n",
              "       -0.7415501 ,  0.44810128,  0.6837585 ,  1.6672035 ,  1.894511  ,\n",
              "       -0.998379  , -2.8618336 ,  1.1272916 , -0.7398779 ,  0.7874045 ,\n",
              "        1.2355528 , -0.648952  ,  2.212763  , -0.69036245,  0.71633327,\n",
              "       -0.29016796, -1.6684973 ,  0.23296297, -1.0226988 , -1.7071369 ,\n",
              "       -0.13675123,  0.6645042 ,  2.4734635 ,  1.1785543 , -0.51956904,\n",
              "        1.2957473 , -0.332151  ,  0.6375144 ,  1.0393924 , -0.9504531 ,\n",
              "        2.023368  , -2.0113947 , -1.1517483 ,  0.81999826, -2.472738  ,\n",
              "        0.02181941,  1.3802015 ,  0.44343823, -1.1783613 , -0.4565884 ,\n",
              "        0.44708022,  0.09318689,  0.3264616 ,  0.7758275 , -1.7762069 ,\n",
              "       -1.0579168 ,  0.66552156,  0.8291992 ,  0.12885833, -0.48040724],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j065v9-C9f-8"
      },
      "source": [
        "Now we will create the word2vec weight matrix in the similar fashion as we created for the Glove vectors and then feed it to the embedding layer of the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6MjdZieu8cC"
      },
      "source": [
        "w2v_weight_matrix = np.zeros((vocab_size,100))\n",
        "novec=[]\n",
        "for word,i in (tokenizer_obj.word_index.items()):\n",
        "  try:\n",
        "    temp=w2v_model.wv[word]\n",
        "    w2v_weight_matrix[i]=temp\n",
        "  except:\n",
        "    novec.append(word)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGbmNVTNu8fZ"
      },
      "source": [
        "# novec"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50An0F0GBx8Q"
      },
      "source": [
        "X=padded_encTweet\n",
        "y=train['target']\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=32)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wA0lzSWB1-k",
        "outputId": "f16aac50-815b-4f6c-b213-de72bfc740aa"
      },
      "source": [
        "#Just copy paste the previous Model that we used for the glove vectors\n",
        "model=Sequential()\n",
        "\n",
        "#Embedding Layer\n",
        "model.add(Embedding(input_dim=vocab_size,output_dim=100,input_length=max_length,weights=[w2v_weight_matrix],trainable=\"False\"))\n",
        "model.add(Dense(units=500,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(units=300,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.9))\n",
        "\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.8))\n",
        "model.add(Dense(units=200,activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "model.add(Flatten()) # To flatten the 3d matrix to 2d ,can use globalpooling1d also\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          11643400  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100, 500)          50500     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 100, 500)          2000      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 500)          0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100, 300)          150300    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 100, 300)          1200      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100, 200)          60200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100, 200)          800       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 200)          0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100, 200)          40200     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100, 200)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20000)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 60003     \n",
            "=================================================================\n",
            "Total params: 12,008,603\n",
            "Trainable params: 12,006,603\n",
            "Non-trainable params: 2,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP0CYxKSB2CB",
        "outputId": "8aedec0a-6c8f-4e1e-dbe8-c5d034c361cd"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(x_train,y_train,epochs=30,batch_size=512 ,validation_data=(x_test,y_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "223/223 [==============================] - 45s 184ms/step - loss: 1.8759 - accuracy: 0.4294 - val_loss: 1.5166 - val_accuracy: 0.3389\n",
            "Epoch 2/30\n",
            "223/223 [==============================] - 41s 184ms/step - loss: 1.0963 - accuracy: 0.4761 - val_loss: 1.1975 - val_accuracy: 0.3389\n",
            "Epoch 3/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 1.0188 - accuracy: 0.5075 - val_loss: 1.2122 - val_accuracy: 0.3389\n",
            "Epoch 4/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 1.0030 - accuracy: 0.5176 - val_loss: 1.3144 - val_accuracy: 0.3389\n",
            "Epoch 5/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.9830 - accuracy: 0.5331 - val_loss: 1.4592 - val_accuracy: 0.3389\n",
            "Epoch 6/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.9473 - accuracy: 0.5566 - val_loss: 1.0743 - val_accuracy: 0.4361\n",
            "Epoch 7/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.8620 - accuracy: 0.6151 - val_loss: 0.7743 - val_accuracy: 0.6915\n",
            "Epoch 8/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.7864 - accuracy: 0.6705 - val_loss: 0.9024 - val_accuracy: 0.5884\n",
            "Epoch 9/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.7525 - accuracy: 0.6933 - val_loss: 0.8165 - val_accuracy: 0.6246\n",
            "Epoch 10/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.7315 - accuracy: 0.7035 - val_loss: 0.8226 - val_accuracy: 0.6126\n",
            "Epoch 11/30\n",
            "223/223 [==============================] - 41s 184ms/step - loss: 0.7120 - accuracy: 0.7130 - val_loss: 0.8208 - val_accuracy: 0.6199\n",
            "Epoch 12/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.7042 - accuracy: 0.7157 - val_loss: 0.7682 - val_accuracy: 0.6611\n",
            "Epoch 13/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6974 - accuracy: 0.7210 - val_loss: 0.7516 - val_accuracy: 0.6631\n",
            "Epoch 14/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6918 - accuracy: 0.7234 - val_loss: 0.7563 - val_accuracy: 0.6430\n",
            "Epoch 15/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6843 - accuracy: 0.7268 - val_loss: 0.7353 - val_accuracy: 0.6629\n",
            "Epoch 16/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6779 - accuracy: 0.7290 - val_loss: 0.7551 - val_accuracy: 0.6471\n",
            "Epoch 17/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6768 - accuracy: 0.7298 - val_loss: 0.7107 - val_accuracy: 0.6823\n",
            "Epoch 18/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6689 - accuracy: 0.7329 - val_loss: 0.6799 - val_accuracy: 0.7181\n",
            "Epoch 19/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6722 - accuracy: 0.7339 - val_loss: 0.7098 - val_accuracy: 0.6891\n",
            "Epoch 20/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6672 - accuracy: 0.7348 - val_loss: 0.7158 - val_accuracy: 0.6842\n",
            "Epoch 21/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6646 - accuracy: 0.7359 - val_loss: 0.7105 - val_accuracy: 0.6805\n",
            "Epoch 22/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6617 - accuracy: 0.7385 - val_loss: 0.6702 - val_accuracy: 0.7164\n",
            "Epoch 23/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6620 - accuracy: 0.7386 - val_loss: 0.6927 - val_accuracy: 0.7018\n",
            "Epoch 24/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6558 - accuracy: 0.7397 - val_loss: 0.6793 - val_accuracy: 0.7163\n",
            "Epoch 25/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6549 - accuracy: 0.7405 - val_loss: 0.6762 - val_accuracy: 0.7155\n",
            "Epoch 26/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6496 - accuracy: 0.7423 - val_loss: 0.6732 - val_accuracy: 0.7204\n",
            "Epoch 27/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6496 - accuracy: 0.7425 - val_loss: 0.6830 - val_accuracy: 0.7095\n",
            "Epoch 28/30\n",
            "223/223 [==============================] - 41s 184ms/step - loss: 0.6462 - accuracy: 0.7447 - val_loss: 0.6849 - val_accuracy: 0.7067\n",
            "Epoch 29/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6377 - accuracy: 0.7484 - val_loss: 0.6747 - val_accuracy: 0.7157\n",
            "Epoch 30/30\n",
            "223/223 [==============================] - 41s 183ms/step - loss: 0.6316 - accuracy: 0.7525 - val_loss: 0.6757 - val_accuracy: 0.7111\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f31f5d54710>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlCWGmWwFin5"
      },
      "source": [
        "<center><h1> Thank You</h1></center>\n",
        "\n",
        "In case of any queries or suggestions, you can reach me over LinkedIn :- https://www.linkedin.com/in/nilaykush/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ObhIrMVGTyM"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}